{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/german-credit.data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lower credit amounts have better credit results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "values = []\n",
    "credit_status_good = data.loc[(data['credit_status'] == 1)]\n",
    "at1 = credit_status_good['credit_amount'].mean() \n",
    "values.append(round(at1,2))\n",
    "\n",
    "credit_status_bad = data.loc[(data['credit_status'] == 2)]\n",
    "at2 = credit_status_bad['credit_amount'].mean()\n",
    "values.append(round(at2,2))\n",
    "\n",
    "plt.ylabel('Credit Amount')\n",
    "langs = ['Credit Status Good','Credit Status Bad']\n",
    "ax.bar(langs,values)\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()),(p.get_x() * 1.005, p.get_height() * 1.005))\n",
    "plt.title('credit status by credit amount')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What men and women spend their money for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "female_data = data.loc[(data['personal_status'] == 'A92') | (data['personal_status'] == 'A95')]\n",
    "plt.figure(figsize=(9,9))\n",
    "plt.title('what women buy')\n",
    "plt.pie(female_data.purpose.value_counts().tolist(), \n",
    "labels=female_data.purpose.value_counts().index.tolist(), \n",
    " autopct='%1.2f%%', textprops={'fontsize':8})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "male_data = data.loc[(data['personal_status'] == 'A91') | (data['personal_status'] == 'A93') | (data['personal_status']  == 'A94')]\n",
    "plt.figure(figsize=(9,9))\n",
    "plt.title('what men buy')\n",
    "plt.pie(male_data.purpose.value_counts().tolist(), \n",
    "labels=male_data.purpose.value_counts().index.tolist(), \n",
    " autopct='%1.2f%%', textprops={'fontsize':8})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of Employment Time to Credit Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "values = []\n",
    "\n",
    "plt.ylim(0, 100)\n",
    "unemployedStatus1=  data.loc[(data['employment_years'] == 'A71') & (data['credit_status'] == 1)].shape[0]\n",
    "unemployedAll =  data.loc[(data['employment_years'] == 'A71')].shape[0]\n",
    "rate0 = unemployedStatus1/unemployedAll\n",
    "values.append(round(rate0*100,2))\n",
    "\n",
    "lessThan1yearStatus1 = data.loc[(data['employment_years'] == 'A72') & (data['credit_status'] == 1)].shape[0]\n",
    "lessThan1yearAll= data.loc[(data['employment_years'] == 'A72')].shape[0]\n",
    "rate1 = lessThan1yearStatus1/lessThan1yearAll\n",
    "values.append(round(rate1*100,2))\n",
    "\n",
    "\n",
    "lessThan4yearStatus1 = data.loc[(data['employment_years'] == 'A73') & (data['credit_status'] == 1)].shape[0] #1<years<4\n",
    "lessThan4yearAll = data.loc[(data['employment_years'] == 'A73')].shape[0]\n",
    "rate2 = lessThan4yearStatus1/lessThan4yearAll\n",
    "values.append(round(rate2*100,2))\n",
    "\n",
    "\n",
    "lessThan7yearStatus1 = data.loc[(data['employment_years'] == 'A74') & (data['credit_status'] == 1)].shape[0] #4<years<7\n",
    "lessThan7yearAll = data.loc[(data['employment_years'] == 'A74')].shape[0]\n",
    "rate3 = lessThan7yearStatus1/lessThan7yearAll\n",
    "values.append(round(rate3*100,2))\n",
    "\n",
    "moreThan7yearStatus1 = data.loc[(data['employment_years'] == 'A75') & (data['credit_status'] == 1)].shape[0] #years>7\n",
    "moreThan7yearAll = data.loc[(data['employment_years'] == 'A75')].shape[0]\n",
    "rate4 = moreThan7yearStatus1/moreThan7yearAll\n",
    "values.append(round(rate4*100,2))\n",
    "\n",
    "labels = ['unemployed','<1', '1<y<4', '4<y<7', '>7']\n",
    "ax.bar(labels,values)\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()) + \"%\",(p.get_x() * 1.005, p.get_height() * 1.005))\n",
    "plt.title('credit score by employment time')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divorcing has a significant impact on credit status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "plt.ylim(0, 100)\n",
    "\n",
    "personal_status_values = []\n",
    "divorced_male_good = data.loc[(data['personal_status'] == 'A91') & (data['credit_status'] == 1)].shape[0]\n",
    "\n",
    "divorced_male_total = data.loc[(data['personal_status'] == 'A91')].shape[0]\n",
    "\n",
    "married_male_good = data.loc[(data['personal_status'] == 'A94') & (data['credit_status'] == 1)].shape[0]\n",
    "\n",
    "married_male_total = data.loc[(data['personal_status'] == 'A94')].shape[0]\n",
    "\n",
    "single_male_good = data.loc[(data['personal_status'] == 'A93') & (data['credit_status'] == 1)].shape[0]\n",
    "\n",
    "single_male_total = data.loc[(data['personal_status'] == 'A93')].shape[0]\n",
    "\n",
    "\n",
    "divorced_male_percentage = divorced_male_good/divorced_male_total\n",
    "married_male_percentage = married_male_good/married_male_total\n",
    "single_male_percentage = single_male_good/single_male_total\n",
    "personal_status_values.append(round(divorced_male_percentage*100, 2))\n",
    "personal_status_values.append(round(married_male_percentage*100, 2))\n",
    "personal_status_values.append(round(single_male_percentage*100, 2))\n",
    "\n",
    "labels = ['divorced male', 'single male', 'married male']\n",
    "ax.bar(labels,personal_status_values)\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()) + \"%\",(p.get_x() * 1.005, p.get_height() * 1.005))\n",
    "\n",
    "plt.title('credit score percentage by personal status')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### credit status for used cars is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "plt.ylim(0, 100)\n",
    "\n",
    "values = []\n",
    "\n",
    "new_car_good = data.loc[(data['purpose'] == 'A40') & (data['credit_status'] == 1)].shape[0] \n",
    "new_car_total = data.loc[(data['purpose'] == 'A40')].shape[0]\n",
    "values.append(round(new_car_good/new_car_total*100, 2))\n",
    "\n",
    "used_car_good = data.loc[(data['purpose'] == 'A41') & (data['credit_status'] == 1)].shape[0] \n",
    "used_car_total = data.loc[(data['purpose'] == 'A41')].shape[0]\n",
    "\n",
    "values.append(round(used_car_good/used_car_total*100, 2))\n",
    "\n",
    "\n",
    "labels = ['new_car', 'used_car']\n",
    "ax.bar(labels,values)\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()) + \"%\",(p.get_x() * 1.005, p.get_height() * 1.005))\n",
    "\n",
    "plt.title('credit score percentage by car type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since sklearn doesn't support classified data, we split classification into columns \n",
    "\n",
    "categorized = pd.get_dummies(data, columns=['checking_account_status', 'credit_history', 'purpose', 'savings_account_status', 'employment_years', 'personal_status', 'guarantors', 'property', 'installment_plans', 'housing', 'job', 'telephone', 'foreign_worker'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(categorized, test_size=0.2)\n",
    "\n",
    "attributes = train.loc[:, train.columns != 'credit_status']\n",
    "credit_status = train.loc[:,['credit_status']]\n",
    "\n",
    "attributes_test = test.loc[:, train.columns != 'credit_status']\n",
    "credit_status_test = test.loc[:,['credit_status']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# logistic regression is to predict credit status\n",
    "# since our dataset is  relatively small, the algorithm expects a bigger iteration number\n",
    "logistic_regression = LogisticRegression(n_jobs=-1, max_iter=20000)\n",
    "logistic_regression.fit(attributes, credit_status)\n",
    "pred_logistic = logistic_regression.predict(attributes_test)\n",
    "\n",
    "log_score = accuracy_score(pred_logistic.round(), credit_status_test)\n",
    "\n",
    "print(\"Credit Status Prediction Using Logistic Regression: \", \"{:.2f}%\".format(log_score * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linear_regression = LinearRegression()\n",
    "linear_regression.fit(attributes, credit_status)\n",
    "pred_linear = linear_regression.predict(attributes_test)\n",
    "\n",
    "lin_score = accuracy_score(pred_linear.round(), credit_status_test)\n",
    "print(\"Credit Status Prediction Using Linear Regression: \", \"{:.2f}%\".format(lin_score * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "NBC = GaussianNB()\n",
    "NBC.fit(attributes, credit_status)\n",
    "pred_gauss = NBC.predict(attributes_test)\n",
    "\n",
    "gaus_score = accuracy_score(pred_gauss.round(), credit_status_test)\n",
    "print(\"Credit Status Prediction Using GaussianNB: \", \"{:.2f}%\".format(gaus_score * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desicion Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt3 = DecisionTreeClassifier(min_samples_split = 3)\n",
    "dt3 = dt3.fit(attributes, credit_status)\n",
    "pred_desicion_tree = dt3.predict(attributes_test)\n",
    "\n",
    "des_score = accuracy_score(pred_desicion_tree.round(), credit_status_test)\n",
    "print(\"Credit Status Prediction Using Desicion Tree Classifier: \", \"{:.2f}%\".format(des_score * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultinominalNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "MNB = MultinomialNB()\n",
    "MNB.fit(attributes, credit_status)\n",
    "pred_MNB = MNB.predict(attributes_test)\n",
    "\n",
    "mult_score = accuracy_score(pred_gauss.round(), credit_status_test)\n",
    "print(\"Credit Status Prediction Using Multinominal: \", \"{:.2f}%\".format(mult_score * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_combined = []\n",
    "\n",
    "s = len(pred_gauss)\n",
    "threshold = 0.7\n",
    "for i in range(s):\n",
    "    credit_good = 0\n",
    "    credit_bad = 0\n",
    "    if gaus_score > threshold:\n",
    "        if pred_gauss[i] == 1:\n",
    "            credit_good += (gaus_score*10)**2\n",
    "        else:\n",
    "            credit_bad += (gaus_score*10)**2\n",
    "    if lin_score > threshold:\n",
    "        if pred_linear[i] == 1:\n",
    "            credit_good += (lin_score*10)**2\n",
    "        else:\n",
    "            credit_bad += lin_score\n",
    "    if log_score > threshold:\n",
    "        if pred_logistic[i] == 1:\n",
    "            credit_good += (log_score*10)**2\n",
    "        else:\n",
    "            credit_bad += (log_score*10)**2\n",
    "    if mult_score > threshold:\n",
    "        if pred_MNB[i] == 1:\n",
    "            credit_good += (mult_score*10)**2\n",
    "        else:\n",
    "            credit_bad += (mult_score*10)**2\n",
    "    \n",
    "    if credit_good == credit_bad:\n",
    "        pred_combined.append(pred_logistic[i])\n",
    "    elif credit_good > credit_bad:\n",
    "        pred_combined.append(1)\n",
    "    else:\n",
    "        pred_combined.append(2)\n",
    "combined_score = accuracy_score(pred_combined, credit_status_test)\n",
    "print(\"Credit Status Prediction Using Multinominal: \", \"{:.2f}%\".format(combined_score * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.xlim(0, 100)\n",
    "Product = ['Logistic Regression','linear regression','GaussianNB','Desicion Tree Classifier','MultinominalNB', 'combined score']\n",
    "Quantity = [log_score * 100, lin_score * 100, gaus_score * 100, des_score * 100, mult_score * 100, combined_score * 100]\n",
    "\n",
    "plt.barh(Product,Quantity)\n",
    "plt.title('Score of Algorithms')\n",
    "plt.ylabel('Algorithms')\n",
    "plt.xlabel('score')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}